### ğŸ“„ **README.md for Faculty RAG Chatbot Project**

---

# ğŸ“ **Faculty RAG Chatbot**  
An AI-powered chatbot that helps students find information about their college faculty, including specializations, emails, and more. This project uses **RAG (Retrieval-Augmented Generation)** with **LangChain**, **Google Gemini API**, **FastAPI**, **LangSmith**, and **Streamlit**.

---

## ğŸš€ **Features**  
- ğŸ¤– Multi-user support  
- ğŸ” Retrieve faculty details (specialization, email, etc.)  
- ğŸ’¬ Conversational memory (understands follow-up questions)  
- ğŸ“Š Uses CSV data for faculty information  
- ğŸŒ Integrated with Google Gemini LLM  
- ğŸ”— Backend (FastAPI) + Frontend (Streamlit)  

---

## âš™ï¸ **Tech Stack**  
- **Backend:** FastAPI, LangChain, LangSmith, Google Gemini API  
- **Frontend:** Streamlit  
- **Database:** Vector Store (for embeddings), CSV (for faculty data)  

---

## ğŸ“ **Project Structure**  
```
faculty-rag-chatbot/
â”œâ”€â”€ app/                        
â”‚   â”œâ”€â”€ main.py                # FastAPI backend
â”‚   â”œâ”€â”€ vector_store/          # Saved vector database
â”‚   â””â”€â”€ data/faculty.csv       # Faculty data (CSV)
â”œâ”€â”€ frontend/                  
â”‚   â””â”€â”€ app.py                 # Streamlit frontend
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ .env                       # API keys (hidden)
â”œâ”€â”€ Procfile                   # For deployment (Render)
â””â”€â”€ README.md                  # Project documentation
```

---

## ğŸš¨ **Prerequisites**  
- Python 3.9+  
- Google Gemini API Key  
- LangSmith Account  

---

## ğŸ”‘ **Environment Setup**  
1. **Clone the repository:**  
   ```bash
   git clone https://github.com/your-username/faculty-rag-chatbot.git
   cd faculty-rag-chatbot
   ```

2. **Create a virtual environment:**  
   ```bash
   python -m venv venv
   source venv/bin/activate  # For Linux/Mac
   venv\Scripts\activate     # For Windows
   ```

3. **Install dependencies:**  
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure environment variables:**  
   Create a `.env` file:  
   ```
   GEMINI_API_KEY=your_gemini_api_key
   LANGCHAIN_API_KEY=your_langchain_api_key
   LANGSMITH_API_KEY=your_langsmith_api_key
   ```

---

## ğŸš€ **Run the Project Locally**  

1. **Start the FastAPI Backend:**  
   ```bash
   uvicorn app.main:app --reload
   ```

2. **Run the Streamlit Frontend:**  
   ```bash
   cd frontend
   streamlit run app.py
   ```

3. **Access the App:**  
   Open [http://localhost:8501](http://localhost:8501) in your browser.

---

## ğŸŒ **Deployment Instructions**  

### 1ï¸âƒ£ **Deploy FastAPI on Render**  
- Push the backend to GitHub  
- Create a new **Web Service** on [Render](https://render.com)  
- Add the **Procfile** for deployment  
- Set environment variables in Render dashboard  

### 2ï¸âƒ£ **Deploy Streamlit on Streamlit Cloud**  
- Push the frontend code to GitHub  
- Go to [Streamlit Cloud](https://streamlit.io/cloud)  
- Click **"New app"**, select your repo, and deploy  

---

## â“ **How It Works**  
- **Query:** Users submit questions about faculty.  
- **Retrieval:** The backend fetches relevant info from the CSV.  
- **Embedding:** Data is embedded using Google Gemini.  
- **Response:** LangChain + LangSmith handle the AI responses.  

---

## ğŸ’¡ **Sample Questions**  
- *"Who is the best teacher for Machine Learning?"*  
- *"What is his email?"* (The bot remembers context!)  
- *"Which faculty specializes in Data Science?"*  

---

## ğŸ¤ **Contributing**  
1. Fork this repo  
2. Create a new branch  
3. Make your changes  
4. Submit a pull request  

---

## ğŸ“œ **License**  
This project is licensed under the MIT License.  

Let me know if you'd like to tweak anything! ğŸš€
